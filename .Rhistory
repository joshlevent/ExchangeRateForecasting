#   0) Packages and functions that we need
# ------------------------------------------------------------------------------
library(readr)
library(httr)
library(xts)
library(dplyr)
# NOTE WELL: DPLYR and XTS require two different implementations of the lag()
# function. Call these explicitly like this: dplyr::lag(df), stats::lag(xts)
library(tsbox)
library(purrr)
library(CADFtest)
library(ggplot2)
library(tidyr)
library(forecast)
library(lubridate)
library(knitr)
library(kableExtra)
# clean objects
rm(list=ls())
# Load user-defined commands and packages
source("UserPackages.R")
# Create an output folder in the current directory
mainDir <- getwd()
outDir <- makeOutDir(mainDir, "ERFOutput")
# define locale for SNB imports
de_CH <- locale(date_format = "%d.%m.%Y")
# 1.1 SARON
# Get data
url <- "https://www.six-group.com/exchanges/downloads/indexdata/hsrron.csv"
response <- GET(url)
data <- content(response, "text")
# Save a cache of the data
timestamp <- format(Sys.time(), "%Y%m%d-%H%M%S")
filename <- paste0("../cache/SARON-", timestamp, ".csv")
write(data, file = filename)
# parse the file contents and save to objects
df <- read_delim(data, delim = "; ", skip = 4,
col_types = "Dd", col_names = c("Date", "Value"),
locale = de_CH, col_select = c(1,2))
SARON <- xts(df$Value, order.by = df$Date)
SARON <- ts_span(SARON, start = "2018-04-03", end ="2023-11-30")
summary(SARON)
var(SARON)
# fill missing dates
date_range <- seq(from = as.Date("2018-04-03"), to = as.Date("2023-11-30"), by = "day")
df <- data.frame(Date = date_range) %>%
left_join(df, by = "Date")
summary(df)
# save data into objects
SARON <- xts(df$Value, order.by = df$Date)
SARONData <- select(df, Date, Value)
# 1.2 SOFR
# Get data
url <- "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1319&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=SOFR&scale=left&cosd=2018-04-03&coed=2024-11-09&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-11-12&revision_date=2024-11-12&nd=2018-04-03"
response <- GET(url)
data <- content(response, "text")
# Save a cache of the data
timestamp <- format(Sys.time(), "%Y%m%d-%H%M%S")
filename <- paste0("../cache/SOFR-", timestamp, ".csv")
write(data, file = filename)
# parse the file contents and save to objects
df <- read_csv(data, skip = 1, col_types = "Dd", col_names = c("Date", "Value"),
na = c("", "ND", "."))
# fill missing dates
date_range <- seq(from = as.Date("2018-04-03"), to = as.Date("2023-11-30"), by = "day")
df <- data.frame(Date = date_range) %>%
left_join(df, by = "Date")
# summary statistics
SOFR <- xts(df$Value, order.by = df$Date)
SOFR <- na.remove(SOFR)
summary(SOFR)
var(SOFR)
# save data into objects
SOFR <- xts(df$Value, order.by = df$Date)
SOFRData <- select(df, Date, Value)
# summary of interpolated data
summary(SOFR)
var(SOFR)
# 1.3 Exchange Rate USD CHF
# Get data
url <- "https://www.federalreserve.gov/datadownload/Output.aspx?rel=H10&series=f838388dca2fd4e8bdfb846f3d2c35df&lastobs=&from=01/01/1971&to=10/09/2024&filetype=csv&label=include&layout=seriescolumn"
response <- GET(url)
data <- content(response, "text")
# Save a cache of the data
timestamp <- format(Sys.time(), "%Y%m%d-%H%M%S")
filename <- paste0("../cache/ER-", timestamp, ".csv")
write(data, file = filename)
# parse the file contents
df <- read_csv(data, skip = 6, col_types = "Dd", col_names = c("Date", "Value"),
na = c("", "ND", "."))
# trim leading and ending NAs
df <- na.trim(df)
# fill missing dates, and then interpolate missing values
date_range <- seq(from = as.Date("2018-04-03"), to = as.Date("2023-11-30"), by = "day")
df <- data.frame(Date = date_range) %>%
left_join(df, by = "Date")
# summary statistics
CHFUSD <- xts(1 / df$Value, order.by = df$Date)
CHFUSD <- na.remove(CHFUSD)
summary(CHFUSD)
var(CHFUSD)
plot(CHFUSD)
# save data into objects
ER <- xts(df$Value, order.by = df$Date)
ERData <- select(df, Date, Value)
# Additional processing for ERData
ERData <- ERData %>%
mutate(CHFUSD = 1 / Value,
LogCHFUSD = log(CHFUSD) * 100, # in percent
ForwardLogCHFUSD = lead(LogCHFUSD), # lead is t+1
LogDifferenceCHFUSD = ForwardLogCHFUSD - LogCHFUSD)
# 1.4 Swiss Policy Actions
# Get new data
# NB: As of 05.12.2023 the url no longer works
# there is a second url that works for now, but we expect it to stop working
# at some point as well.
# Therefore, using the cache instead
url <- "https://data.snb.ch/json/table/getFile?fileId=2eb5650771935a870db45db19f098567acfe49cf8e9872727243fc1885238707&pageViewTime=20231127_172937&lang=en"
url <- "https://data.snb.ch/json/table/getFile?fileId=8fca4acf22ada6dbbce962c9c1e7e2e6a2bfa5383345bcfc638961dd7f0a3577&pageViewTime=20231205_165257&lang=en"
response <- GET(url)
data <- content(response, "text")
data <- "../cache/SwissPolicy1-20231205-140338.csv"
# parse the file contents
df <- read_delim(data, delim = ";", col_types = "Dcd", skip = 4,
na = c("", "ND", "."), col_names = c("Date", "D0", "Value"))
# additional transformations to select only policy rate
df <- filter(df, D0 == "LZ")
df <- select(df, Date, Value)
df <- na.trim(df)
# save to xts object
SwissPolicyRate <- xts(df$Value, order.by = df$Date)
# transformations to select policy changes
SwissPolicyChange1 <- ts_diff(SwissPolicyRate)
SwissPolicyChange1 <- subset(SwissPolicyChange1, value != 0)
# Get old data
url <- "https://data.snb.ch/json/table/getFile?fileId=598a401ddfd66075bc2be3845d5f21e3ddf5e22d083ea30424af2e633e374778&pageViewTime=20231127_173150&lang=en"
response <- GET(url)
data <- content(response, "text")
# currently the site gives an error, therefore we use the cache
data <- "../cache/SwissPolicy2-20231205-140338.csv"
# parse the file contents
df <- read_delim(data, delim = ";", col_types = "Dcd", skip = 4,
na = c("", "ND", "."), col_names = c("Date", "D0", "Value"))
# additional transformations to select only policy rate
df <- df %>% filter(D0 == "UG")
df <- select(df, Date, Value)
df <- na.trim(df)
# save to xts object
SwissPolicyRate <- xts(df$Value, order.by = df$Date)
# transformations to select policy changes
SwissPolicyChange2 <- ts_diff(SwissPolicyRate)
SwissPolicyChange2 <- subset(SwissPolicyChange2, value != 0)
# combine old and new data
SwissPolicyChange <- rbind(SwissPolicyChange1, SwissPolicyChange2)
# 1.5 USA Policy Actions
# Get data
url <- "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1318&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=DFEDTARU&scale=left&cosd=2018-01-01&coed=2023-11-27&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily%2C%207-Day&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2023-11-27&revision_date=2023-11-27&nd=2008-12-16"
response <- GET(url)
data <- content(response, "text")
# Save a cache of the data
timestamp <- format(Sys.time(), "%Y%m%d-%H%M%S")
filename <- paste0("../cache/USPolicy-", timestamp, ".csv")
write(data, file = filename)
# parse the file contents and save to objects
df <- read_csv(data, skip = 1, col_types = "Dd", col_names = c("Date", "Value"))
USPolicyRate <- xts(df$Value, order.by = df$Date)
# transformations to select policy changes
USPolicyChange <- ts_diff(USPolicyRate)
USPolicyChange <- subset(USPolicyChange, value != 0)
# 1.6 Combining and trimming exchange rate and interest rate timeseries
# Select and rename relevant columns
SARONData <- SARONData %>% select(Date, SARON = Value)
SOFRData <- SOFRData %>% select(Date, SOFR = Value)
ERData <- ERData %>% select(Date, LogDifferenceCHFUSD, LogCHFUSD, CHFUSD)
# Combine dataframes
combinedData <- reduce(list(SARONData, SOFRData, ERData), full_join, by = "Date")
# Identify valid date range
first_valid_date <- combinedData %>% filter(!is.na(SARON) & !is.na(SOFR) & !is.na(LogDifferenceCHFUSD)) %>% summarize(first_date = min(Date)) %>% pull(first_date)
last_valid_date <- combinedData %>% filter(!is.na(SARON) & !is.na(SOFR) & !is.na(LogDifferenceCHFUSD)) %>% summarize(last_date = max(Date)) %>% pull(last_date)
# Trim data to valid range
trimmedData <- combinedData %>% filter(Date >= first_valid_date & Date <= last_valid_date)
# summary of final dataframe
summary(trimmedData)
# checking whether the log difference approximation is suitable
max(trimmedData$LogDifferenceCHFUSD, na.rm = TRUE)
min(trimmedData$LogDifferenceCHFUSD, na.rm = TRUE)
# Calculate the interest rate differential
# this is i^CH - i^US
trimmedData <- trimmedData %>%
mutate(IRd = SARON - SOFR)
# split data into timeseries objects
IRd <- xts(trimmedData$IRd, order.by = trimmedData$Date)
ERd <- xts(trimmedData$LogDifferenceCHFUSD, order.by = trimmedData$Date)
# check for stationarity with u Root test
uRootER <- CADFtest(ERd, max.lag.y = 10, type = "drift", criterion = "BIC")
summary(uRootER)
# this is stationary, good!
uRootIRd <- CADFtest(IRd, max.lag.y = 10, type = "drift", criterion = "BIC")
summary(uRootIRd)
# this is not stationary, bad!
# create a first difference variable
# this is IRd_t - IRd_t-1 (lag 1)
IRdd <- IRd - stats::lag(IRd)
# check the first difference for
uRootFDIR <- CADFtest(IRdd, max.lag.y = 10, type = "drift", criterion = "BIC")
summary(uRootFDIR)
# plot first difference of interest rate differential
ts_plot(IRdd)
p <- autoplot(IRdd)
p <- ggLayout(p) +
labs(title = "First differences of Interest Rate differential between Switzerland and USA") +
scale_y_continuous(breaks = seq(-3, 3, by = 0.5)) +
theme(panel.grid.minor.x = element_line(colour = "black",linewidth=0.1,linetype="dotted"))
p
# plot first difference of log exchange rates
ts_plot(ERd)
p <- autoplot(ERd)
p <- ggLayout(p) +
labs(title = "First differences of log exchange rate between Switzerland and USA") +
scale_y_continuous(breaks = seq(-3, 3, by = 0.5)) +
theme(panel.grid.minor.x = element_line(colour = "black",linewidth=0.1,linetype="dotted"))
p
# plot both the interest rates
InterestRatesLong <- pivot_longer(trimmedData, cols = c(SARON, SOFR), names_to = "id", values_to = "value")
InterestRatesLong <- select(InterestRatesLong, Date, id, value)
ts_plot(InterestRatesLong)
p <- ggplot(InterestRatesLong, aes(x = Date, y = value, color = id)) +
geom_line()
p <- ggLayout(p) +
labs(title = "Swiss and US Interest Rates (Secured Overnight) Over Time") +
scale_color_manual(values = c("SARON" = "firebrick4", "SOFR" = "blue4"),
labels = c("SARON" = "Switzerland", "SOFR" = "United States")) +
scale_y_continuous(breaks = seq(-1, 5.5, by = 0.5)) +
theme(panel.grid.minor.x = element_line(colour = "black",linewidth=0.1,linetype="dotted"))
p
p <- plotCCF(ERd, IRdd, lag.max = 365)
p <- ggLayout(p) +
labs(title = "Cross Correlation Function of Interest Rate differential and Exchange Rate")
p
# Perform simple regression analysis
# THIS IS AN IN-SAMPLE TEST (BEST CASE)
result <- lm(ERd ~ IRdd)
summary(result)
# Check autocorrelation of residuals
pdf("empirical_residuals.pdf", width = 11.7, height = 8.3)
dev.off()
checkresiduals(result)+theme_minimal()
# calculate error measures for empirical model
EmpiricalError = ts(result$residuals)
ME2 = mean(EmpiricalError)
T=length(EmpiricalError)
FEV2 = var(EmpiricalError)*(T-1)/T
MSFE2 = mean(EmpiricalError^2)
RMSFE2 = sqrt(MSFE2)
MAFE2 = mean(abs(EmpiricalError))
# Create forecast with theoretical model
trimmedData$DailyRate <- (1 + trimmedData$IRd / 100)^(1/365) - 1
trimmedData$TheoryForecast = dplyr::lag(trimmedData$DailyRate + trimmedData$LogCHFUSD)
trimmedData$TheoryCHFUSD = exp(trimmedData$TheoryForecast/100)
CHFUSD = xts(trimmedData$CHFUSD, order.by = trimmedData$Date)
TheoryCHFUSD = xts(trimmedData$TheoryCHFUSD, order.by = trimmedData$Date)
ts_plot(CHFUSD, TheoryCHFUSD)
# calculate error measures for theoretical model
trimmedData$TheoryError = trimmedData$LogCHFUSD - trimmedData$TheoryForecast
TheoryError = xts(trimmedData$TheoryError, order.by = trimmedData$Date)
TheoryError <- na.trim(TheoryError)
ts_plot(TheoryError)
ME1 = mean(TheoryError)
T=length(TheoryError)
FEV1 = var(TheoryError)*(T-1)/T
MSFE1 = mean(TheoryError^2)
RMSFE1 = sqrt(MSFE1)
MAFE1 = mean(abs(TheoryError))
# Check residuals of theoretical model
TheoryList = list(residuals = TheoryError)
checkresiduals(TheoryList)+theme_minimal()
# Fit ARIMA model for benchmark
arima_model <- Arima(ERd, order = c(1, 0, 0), include.constant= FALSE, method = "ML")
summary(arima_model)
checkresiduals(arima_model)
forecast <- forecast(arima_model, h = 365)
plot(forecast)
ARIMAError = arima_model$residuals
ARIMAError = ts_span(ARIMAError, end = "2067")
ME3 = mean(ARIMAError)
T=length(ARIMAError)
FEV3 = var(ARIMAError)*(T-1)/T
MSFE3 = mean(ARIMAError^2)
RMSFE3 = sqrt(MSFE3)
MAFE3 = mean(abs(ARIMAError))
# add random walk forecast, previous value
trimmedData$RWForecast = dplyr::lag(trimmedData$LogCHFUSD)
trimmedData$RWError = trimmedData$LogCHFUSD - trimmedData$RWForecast
RWError = ts(trimmedData$RWError)
RWError = na.trim(RWError)
ME4 = mean(RWError)
T=length(RWError)
FEV4 = var(RWError)*(T-1)/T
MSFE4 = mean(RWError^2)
RMSFE4 = sqrt(MSFE4)
MAFE4 = mean(abs(RWError))
# Check residuals of random walk model
RWList = list(residuals = RWError)
checkresiduals(RWList)+theme_minimal()
# draw table of various error measures for all 3 models
Table = c(ME1^2/MSFE1, ME2^2/MSFE2, ME3^2/MSFE3, ME4^2/MSFE4)
Table = rbind(Table, c(FEV1/MSFE1, FEV2/MSFE2, FEV3/MSFE3, FEV4/MSFE4))
Table = rbind(Table, c(RMSFE1, RMSFE2, RMSFE3, RMSFE4))
Table = rbind(Table, c(MAFE1, MAFE2, MAFE3, MAFE4))
Table = round(Table, 2)
colnames(Table) = c("Theoretical", "Empirical", "AR(1)", "Random Walk")
rownames(Table) = c("Share bias", "Share variance", "RMSFE", "MAFE")
Table
# Diebold Mariano test
# a function allows us to test all combinations of a list
dm_test_pairs <- function(error_list) {
if(is.null(names(error_list))) {
stop("Please provide names for the error series in the list.")
}
n <- length(error_list)
results_matrix <- matrix(NA, n, n, dimnames = list(names(error_list), names(error_list)))
for (i in 1:(n-1)) {
for (j in (i+1):n) {
model1_error <- error_list[[i]]
model2_error <- error_list[[j]]
test_result <- dm.test(model1_error, model2_error, h = 1, power = 2)
results_matrix[i, j] <- paste(round(test_result$statistic, 3), " (", round(test_result$p.value, 2), ")", sep = "")
results_matrix[j, i] <- paste(round(test_result$statistic * -1, 3), " (", round(test_result$p.value, 2), ")", sep = "")
}
}
return(results_matrix)
}
errors_list <- list(
Theoretical = TheoryError,
Empirical = EmpiricalError,
"AR(1)"= ARIMAError,
"Random Walk" = RWError
)
dm_test <- dm_test_pairs(errors_list)
View(errors_list)
dm_test
View(result)
? CADFtest
View(SOFR)
# 1.2 SOFR
# Get data
url <- "https://fred.stlouisfed.org/graph/fredgraph.csv?bgcolor=%23e1e9f0&chart_type=line&drp=0&fo=open%20sans&graph_bgcolor=%23ffffff&height=450&mode=fred&recession_bars=on&txtcolor=%23444444&ts=12&tts=12&width=1319&nt=0&thu=0&trc=0&show_legend=yes&show_axis_titles=yes&show_tooltip=yes&id=SOFR&scale=left&cosd=2018-04-03&coed=2024-11-09&line_color=%234572a7&link_values=false&line_style=solid&mark_type=none&mw=3&lw=2&ost=-99999&oet=99999&mma=0&fml=a&fq=Daily&fam=avg&fgst=lin&fgsnd=2020-02-01&line_index=1&transformation=lin&vintage_date=2024-11-12&revision_date=2024-11-12&nd=2018-04-03"
response <- GET(url)
data <- content(response, "text")
# Save a cache of the data
timestamp <- format(Sys.time(), "%Y%m%d-%H%M%S")
filename <- paste0("../cache/SOFR-", timestamp, ".csv")
write(data, file = filename)
# parse the file contents and save to objects
df <- read_csv(data, skip = 1, col_types = "Dd", col_names = c("Date", "Value"),
na = c("", "ND", "."))
View(df)
setwd("~/Library/CloudStorage/OneDrive-Personal/01 Economics/03 Semester 3 Classes/02 Applied Macroeconometrics/ExchangeRateForecasting")
source("~/Library/CloudStorage/OneDrive-Personal/01 Economics/03 Semester 3 Classes/02 Applied Macroeconometrics/ExchangeRateForecasting/ExchangeRateForecasting.R", echo=TRUE)
source("~/Library/CloudStorage/OneDrive-Personal/01 Economics/03 Semester 3 Classes/02 Applied Macroeconometrics/ExchangeRateForecasting/ExchangeRateForecasting.R", echo=TRUE)
setwd("~/Library/CloudStorage/OneDrive-Personal/01 Economics/03 Semester 3 Classes/02 Applied Macroeconometrics/ExchangeRateForecasting")
source("~/Library/CloudStorage/OneDrive-Personal/01 Economics/03 Semester 3 Classes/02 Applied Macroeconometrics/ExchangeRateForecasting/ExchangeRateForecasting.R", echo=TRUE)
View(errors_list)
ARIMAError = arima_model$residuals
ARIMAError = ts_span(ARIMAError, end = "2066")
ME3 = mean(ARIMAError)
T=length(ARIMAError)
FEV3 = var(ARIMAError)*(T-1)/T
MSFE3 = mean(ARIMAError^2)
RMSFE3 = sqrt(MSFE3)
MAFE3 = mean(abs(ARIMAError))
# add random walk forecast, previous value
trimmedData$RWForecast = dplyr::lag(trimmedData$LogCHFUSD)
trimmedData$RWError = trimmedData$LogCHFUSD - trimmedData$RWForecast
RWError = ts(trimmedData$RWError)
RWError = na.trim(RWError)
ME4 = mean(RWError)
T=length(RWError)
FEV4 = var(RWError)*(T-1)/T
MSFE4 = mean(RWError^2)
RMSFE4 = sqrt(MSFE4)
MAFE4 = mean(abs(RWError))
# Check residuals of random walk model
RWList = list(residuals = RWError)
pdf("random_walk_residuals.pdf", width = 11.7, height = 8.3)
checkresiduals(RWList)+theme_minimal()
dev.off()
# draw table of various error measures for all 3 models
Table = c(ME1^2/MSFE1, ME2^2/MSFE2, ME3^2/MSFE3, ME4^2/MSFE4)
Table = rbind(Table, c(FEV1/MSFE1, FEV2/MSFE2, FEV3/MSFE3, FEV4/MSFE4))
Table = rbind(Table, c(RMSFE1, RMSFE2, RMSFE3, RMSFE4))
Table = rbind(Table, c(MAFE1, MAFE2, MAFE3, MAFE4))
Table = round(Table, 2)
colnames(Table) = c("Theoretical", "Empirical", "AR(1)", "Random Walk")
rownames(Table) = c("Share bias", "Share variance", "RMSFE", "MAFE")
Table
save(Table, file = "main_error_table.RData")
# Diebold Mariano test
# a function allows us to test all combinations of a list
dm_test_pairs <- function(error_list) {
if(is.null(names(error_list))) {
stop("Please provide names for the error series in the list.")
}
n <- length(error_list)
results_matrix <- matrix(NA, n, n, dimnames = list(names(error_list), names(error_list)))
for (i in 1:(n-1)) {
for (j in (i+1):n) {
model1_error <- error_list[[i]]
model2_error <- error_list[[j]]
test_result <- dm.test(model1_error, model2_error, h = 1, power = 2)
results_matrix[i, j] <- paste(round(test_result$statistic, 3), " (", round(test_result$p.value, 2), ")", sep = "")
results_matrix[j, i] <- paste(round(test_result$statistic * -1, 3), " (", round(test_result$p.value, 2), ")", sep = "")
}
}
return(results_matrix)
}
errors_list <- list(
Theoretical = TheoryError,
Empirical = EmpiricalError,
"AR(1)"= ARIMAError,
"Random Walk" = RWError
)
dm_test <- dm_test_pairs(errors_list)
dm_test
save(dm_test, file = "dm_test_table.RData")
# combine US and Swiss policy changes
AllPolicyChange = rbind(USPolicyChange,SwissPolicyChange)
# extract the dates from the time series object
dates <- as.Date(time(AllPolicyChange))
# restrict the range to our sample range
dates <- dates[dates >= first_valid_date & dates <= last_valid_date]
# Function to get dates 2 days before and after a given date
expand_dates <- function(date) {
seq(from = date - 2, to = date + 2, by = "days")
}
# Apply the function to each date and create a vector of all relevant dates
expanded_dates <- unique(unlist(lapply(dates, expand_dates)))
trimmedData$IRdd = trimmedData$IRd - dplyr::lag(trimmedData$IRd)
filteredData <- trimmedData[trimmedData$Date %in% expanded_dates, ]
IRd_narrow = xts(filteredData$IRd, order.by = filteredData$Date)
# as before we use the IRdd for the estimated model
IRdd_narrow <- xts(filteredData$IRdd, order.by = filteredData$Date)
ERd_narrow = xts(filteredData$LogDifferenceCHFUSD, order.by = filteredData$Date)
result_narrow <- lm(ERd_narrow ~ IRdd_narrow)
narrow_empirical_results <- summary(result_narrow)
narrow_empirical_results
# Check autocorrelation of residuals
pdf("residuals_narrow.pdf", width = 11.7, height = 8.3)
checkresiduals(result_narrow)+theme_minimal()
dev.off()
# Fit ARIMA model
arima_model_narrow = Arima(ERd_narrow, order = c(1, 0, 0), include.constant= FALSE, method = "ML")
pdf("arima_narrow.pdf", width = 11.7, height = 8.3)
summary(arima_model_narrow)
checkresiduals(arima_model_narrow)
forecast <- forecast(arima_model_narrow, h = 365)
plot(forecast)
dev.off()
arima_narrow_error = arima_model_narrow$residuals
rw_narrow_error = ts(filteredData$RWError)
theory_narrow_error = ts(filteredData$TheoryError)
empirical_narrow_error = ts(result_narrow$residuals)
# check residuals for theoretical model
theory_narrow_list = list(residuals = theory_narrow_error)
pdf("theory_residuals_narrow.pdf", width = 11.7, height = 8.3)
checkresiduals(theory_narrow_list)+theme_minimal()
dev.off()
# check residuals for rw model
rw_narrow_list = list(residuals = rw_narrow_error)
pdf("rw_residuals_narrow.pdf", width = 11.7, height = 8.3)
checkresiduals(rw_narrow_list)+theme_minimal()
dev.off()
calculate_error_measures <- function(error_series_list) {
# Check if the list has names
if(is.null(names(error_series_list))) {
stop("Please provide names for the error series in the list.")
}
# Initialize a list to store calculated measures for each error series
measures_list <- list()
for (error_series_name in names(error_series_list)) {
error_series <- error_series_list[[error_series_name]]
T <- length(error_series)
ME <- mean(error_series)
FEV <- var(error_series) * (T - 1) / T
MSFE <- mean(error_series^2)
RMSFE <- sqrt(MSFE)
MAFE <- mean(abs(error_series))
# Compute Share Bias and Share Variance
ShareBias <- ME^2 / MSFE
ShareVariance <- FEV / MSFE
# Store the measures in the list
measures_list[[error_series_name]] <- c(ShareBias, ShareVariance, RMSFE, MAFE)
}
# Convert the list to a data frame
error_table <- do.call(cbind, measures_list)
# Set column and row names
rownames(error_table) <- c("Share bias", "Share variance", "RMSFE", "MAFE")
# Round the table values
return(round(error_table, 2))
}
error_series_list <- list(
Theoretical = theory_narrow_error,
Empirical = empirical_narrow_error,
"AR(1)"= arima_narrow_error,
"Random Walk" = rw_narrow_error
)
error_table <- calculate_error_measures(error_series_list)
print(error_table)
save(error_table, file = "narrow_error_table.RData")
narrow_dm_test <- dm_test_pairs(error_series_list)
narrow_dm_test
save(narrow_dm_test, file = "narrow_dm_test_table.RData")
